{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlaoZez9awUq/VFZfnwAvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/topcat101-cmd/asdasdasd/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHoeUFemUoR"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaLLlTQ32dvU"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "# Lets define some constants to help us later on"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvkXDKYc2zzj"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP_nlslke4U8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c33a67c4-0b00-4923-9116-96ffe09c0949"
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "train.head() # the species column is now gone"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJgQUJAON-c7"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle and repeat if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    return dataset.batch(batch_size)\n",
        "#the above is just one function, which would be used to train the model\n",
        "# Feature columns describe how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X_8nEEPBEo7",
        "outputId": "22b5d832-7848-4fd3-ecae-41c36cd72e7c"
      },
      "source": [
        "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier( #The estimator just stores premade model from tensorflow, such as the DNNClassfier\n",
        "    feature_columns=my_feature_columns,#then feature_columns would be passed through to my feature columns\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpncplp539\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpncplp539', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e6b8r0KEhF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc6b084-26ac-4480-f5d5-6825ccda0a1d"
      },
      "source": [
        "#training the model\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True), #this would return to us a function, which is to call the function\n",
        "    steps=5000\n",
        ")\n",
        "#this includes a lambda to acoid creating an inner function previosly\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpncplp539/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 2.1932642, step = 0\n",
            "INFO:tensorflow:global_step/sec: 377.584\n",
            "INFO:tensorflow:loss = 1.2237473, step = 100 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 510.604\n",
            "INFO:tensorflow:loss = 1.0889754, step = 200 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 437.505\n",
            "INFO:tensorflow:loss = 1.0367081, step = 300 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.409\n",
            "INFO:tensorflow:loss = 1.001585, step = 400 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.014\n",
            "INFO:tensorflow:loss = 0.96201205, step = 500 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 466.916\n",
            "INFO:tensorflow:loss = 0.93947566, step = 600 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 445.262\n",
            "INFO:tensorflow:loss = 0.91560376, step = 700 (0.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 454.206\n",
            "INFO:tensorflow:loss = 0.89150333, step = 800 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.455\n",
            "INFO:tensorflow:loss = 0.8757391, step = 900 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 450.571\n",
            "INFO:tensorflow:loss = 0.8589981, step = 1000 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.136\n",
            "INFO:tensorflow:loss = 0.8439933, step = 1100 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.121\n",
            "INFO:tensorflow:loss = 0.8241324, step = 1200 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 464.251\n",
            "INFO:tensorflow:loss = 0.8143849, step = 1300 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 452.415\n",
            "INFO:tensorflow:loss = 0.7913683, step = 1400 (0.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.261\n",
            "INFO:tensorflow:loss = 0.7808301, step = 1500 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 406.867\n",
            "INFO:tensorflow:loss = 0.7590525, step = 1600 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.758\n",
            "INFO:tensorflow:loss = 0.7548961, step = 1700 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.249\n",
            "INFO:tensorflow:loss = 0.7385037, step = 1800 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.245\n",
            "INFO:tensorflow:loss = 0.7246449, step = 1900 (0.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.031\n",
            "INFO:tensorflow:loss = 0.7118299, step = 2000 (0.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.521\n",
            "INFO:tensorflow:loss = 0.7084626, step = 2100 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 417.646\n",
            "INFO:tensorflow:loss = 0.6962395, step = 2200 (0.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.953\n",
            "INFO:tensorflow:loss = 0.68834335, step = 2300 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.772\n",
            "INFO:tensorflow:loss = 0.67680883, step = 2400 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.507\n",
            "INFO:tensorflow:loss = 0.66815794, step = 2500 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.749\n",
            "INFO:tensorflow:loss = 0.65655047, step = 2600 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.009\n",
            "INFO:tensorflow:loss = 0.64658284, step = 2700 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 465.187\n",
            "INFO:tensorflow:loss = 0.6313161, step = 2800 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.018\n",
            "INFO:tensorflow:loss = 0.62566257, step = 2900 (0.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 463.283\n",
            "INFO:tensorflow:loss = 0.61547875, step = 3000 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 443.055\n",
            "INFO:tensorflow:loss = 0.61230165, step = 3100 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 455.453\n",
            "INFO:tensorflow:loss = 0.6026497, step = 3200 (0.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 470.173\n",
            "INFO:tensorflow:loss = 0.5968621, step = 3300 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 477.162\n",
            "INFO:tensorflow:loss = 0.5783262, step = 3400 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 436.209\n",
            "INFO:tensorflow:loss = 0.5801556, step = 3500 (0.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 432.247\n",
            "INFO:tensorflow:loss = 0.5748707, step = 3600 (0.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 468.308\n",
            "INFO:tensorflow:loss = 0.58566564, step = 3700 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.175\n",
            "INFO:tensorflow:loss = 0.55638546, step = 3800 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 448.695\n",
            "INFO:tensorflow:loss = 0.5567212, step = 3900 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.469\n",
            "INFO:tensorflow:loss = 0.54451674, step = 4000 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.56\n",
            "INFO:tensorflow:loss = 0.5475372, step = 4100 (0.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.191\n",
            "INFO:tensorflow:loss = 0.54164404, step = 4200 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.028\n",
            "INFO:tensorflow:loss = 0.535769, step = 4300 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.471\n",
            "INFO:tensorflow:loss = 0.51385796, step = 4400 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 446.629\n",
            "INFO:tensorflow:loss = 0.5252544, step = 4500 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 442.156\n",
            "INFO:tensorflow:loss = 0.51626825, step = 4600 (0.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.029\n",
            "INFO:tensorflow:loss = 0.509915, step = 4700 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.34\n",
            "INFO:tensorflow:loss = 0.5084821, step = 4800 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.961\n",
            "INFO:tensorflow:loss = 0.48454106, step = 4900 (0.194 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpncplp539/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.4938093.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fe286f70690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnUeMsRD9Q1N",
        "outputId": "3bba3350-30ed-4472-f9b8-a4f41c1de830"
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "clear_output()\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy: 0.800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJOqjXJfMU9N",
        "outputId": "38c26e3d-6bb5-4abd-d292-05cc75f6787c"
      },
      "source": [
        "def input_fn(features, batch_size=256):\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size) #What is this doing, is to make a prediction\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'] \n",
        "predict = {} #predict dictornary\n",
        "\n",
        "print(\"Please type numeric values as prompted.\")\n",
        "for feature in features:\n",
        "  valid = True\n",
        "  while valid: \n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict[feature] = [float(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "for pred_dict in predictions: #with every prediction comes a dictornary\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))\n",
        "    #This allows the user to type in sum numbers 'SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type numeric values as prompted.\n",
            "SepalLength: 2.4\n",
            "SepalWidth: 2.6\n",
            "PetalLength: 6.5\n",
            "PetalWidth: 6.3\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpncplp539/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Virginica\" (77.4%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}